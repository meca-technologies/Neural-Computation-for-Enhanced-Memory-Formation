# Neural-Computation-for-Enhanced-Memory-Formation
Machine learning proposition that outlines how to capture logical aspects of neural computation and memory formation.

The goal of this proposal is to integrate logical-inferential and symbolic reasoning categories  including symbol grounding and rule-based reasoning â€“ with neural-computational categories, with the goal of improving memory formation of machine learning systems. Present-day neural networks can perform well at pattern recognition and associative memory tasks but, with a few notable exceptions, tend to lack proper inference and reasoning capabilities (eg, logical reasoning, knowledge representation, and rule-based reasoning). We propose to consider integrating inference mechanisms in neural architectures. This combination could lead to models that capture both statistical regularities in data and logical relationships among concepts. This proposal lays out the basic components of this integration, including the combination of symbolic representations and integration of logical rules, as well as training strategies for learning the logical inference processes alongside neural-computation processes. Its potential applications to tasks such as natural language, decision-making and symbolic reasoning are discussed.

# Introduction:

For example, modern neural networks do a very poor job of reproducing logical computations, and they are not very good at accounting for the logical properties of thoughts and memories in terms of just the lower-level principles of learning and neural activity.

Motivation for integrating logical inference with neural computation to address these limitations.

The importance of the ability to form memory in machine-learning systems for certain tasks where long-term reasoning and complex decision-making are required.
